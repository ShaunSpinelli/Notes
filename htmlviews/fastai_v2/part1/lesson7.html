<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimal-ui">
    <title>Lesson 7</title>
    <link type="text/css" rel="stylesheet" href="../../assets/css/github-markdown.css">
    <link type="text/css" rel="stylesheet" href="../../assets/css/pilcrow.css">
    <link type="text/css" rel="stylesheet" href="../../assets/css/hljs-github.min.css"/>
  </head>
  <body>
    <article class="markdown-body"><h1 id="lesson-7"><a class="header-link" href="#lesson-7"></a>Lesson 7</h1>
<p><a href="http://forums.fast.ai/t/wiki-lesson-7/9405">Lesson 7 Wiki</a></p>
<ul class="list">
<li>fist half in rnn</li>
</ul>
<p>batch normalization</p>
<p>semantic segmentation</p>
<h2 id="computer-vision---starts-at-1:02"><a class="header-link" href="#computer-vision---starts-at-1:02"></a>Computer vision - starts at 1:02</h2>
<p>Cifar 10 - small data set of images with images of small sizes</p>
<p>stats - mean and standard deviation of channel (we need this no normalise data)</p>
<p>tfms - transform data</p>
<p>line 9 - creating a customer learner just a fully connected model</p>
<hr>
<p>fully convelutional network</p>
<p>create a CNN- convolution</p>
<p>stride 2 conv. we move the kernel by two so we end up halving the resolution</p>
<p>adaptive max pool- last layer we do a maxpool just specify what size we want the output image second last we make a 1x1 max pool</p>
<p>then put it in a linear layer with output to amount of classes</p>
<hr>
<p>padding- so we can get the feature at the edges of the image</p>
<hr>
<p><a href="https://www.youtube.com/watch?v=dXB-KQYkzNU">Batch norm</a></p>
<p>pick up lesson at 1:56</p>
    </article>
  </body>
</html>
